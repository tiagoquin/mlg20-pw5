{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLG: Lab SOM (Part 1)\n",
    "\n",
    "Throughout the laboratories, questions that you should try to answer are highlighted as follows :\n",
    "\n",
    "<p style=\"background-color:#006600; color:#fff;padding:5px; font-weight:bold\">Q: Try to answer these questions / run the proposed experiments for your own comprehension. </p>\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this laboratory, we will work with a different type of problem called unsupervised learning.\n",
    "When we talk about unsupervised learning, it means that we are trying to find **hidden structure** in unlabeled data. Therefore, no simple measure exists to evaluate a potential solution.\n",
    "\n",
    "\n",
    "We will focus on a commonly used algorithm to solve this kind of problem called \"Self Organizing Maps\".\n",
    "As you saw in the theoretical part of the course, the main advantage of this algorithm is its topological ordering, which means that the maps can be visualized as **elastic grids**. Therefore they can be easily plotted.\n",
    "\n",
    "## Pre-requisites\n",
    "\n",
    "For the following exercises, you could need several new packages. Install them as follows:\n",
    "\n",
    "    $ pip install seaborn\n",
    "    \n",
    "After these, you should be able to import them. If any error occurs after, it maybe because some modules are missing. Try to install them with:\n",
    "\n",
    "    $ conda install name_of_the_missing_module\n",
    "\n",
    "## Exercise 1 : Animals database clustering with Kohonen Self-Organizing Maps\n",
    "\n",
    "### Dataset information\n",
    "\n",
    "In the general sense, the Self-Organizing Maps algorithm is used as a dimensionality reduction algorithm. It transforms a \"n-dimensional\" data into a 2-dimensional elastic grid.\n",
    "\n",
    "In this particular exercise, we will look at an example from the course: applying SOM on animals data.\n",
    "\n",
    "Each row is an animal, and is constructed by the presence (1) or absence (0) of 13 different attributes. You can look at the plot hereafter, or generate it yourself with this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import KohonenUtils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as pl\n",
    "from matplotlib import cm\n",
    "import matplotlib.patches as mpatches\n",
    "import math\n",
    "%matplotlib inline\n",
    "\n",
    "matrix = np.array([[1,0,0,1,0,0,0,0,1,0,0,1,0],\n",
    "                   [1,0,0,1,0,0,0,0,1,0,0,0,0],\n",
    "                   [1,0,0,1,0,0,0,0,1,0,0,0,1],\n",
    "                   [1,0,0,1,0,0,0,1,1,0,0,1,1],\n",
    "                   [1,0,0,1,0,0,0,0,1,1,0,1,0],\n",
    "                   [1,0,0,1,0,0,0,0,1,1,0,1,0],\n",
    "                   [0,1,0,1,0,0,0,0,1,1,0,1,0],\n",
    "                   [0,1,0,0,1,1,0,0,0,1,0,0,0],\n",
    "                   [0,1,0,0,1,1,0,0,0,0,1,0,0],\n",
    "                   [0,1,0,0,1,1,0,1,0,1,1,0,0],\n",
    "                   [1,0,0,0,1,1,0,0,0,1,0,0,0],\n",
    "                   [0,0,1,0,1,1,0,0,0,1,1,0,0],\n",
    "                   [0,0,1,0,1,1,0,1,0,1,1,0,0],\n",
    "                   [0,0,1,0,1,1,1,1,0,0,1,0,0],\n",
    "                   [0,0,1,0,1,1,1,1,0,0,1,0,0],\n",
    "                   [0,0,1,0,1,1,1,0,0,0,0,0,0]])\n",
    "\n",
    "animals = pd.DataFrame(matrix.astype(float),columns=['small', 'medium', 'big', '2legs', '4legs', 'hair', 'hooves',\n",
    "                                'mane', 'feathers', 'hunt', 'run', 'fly', 'swim'])\n",
    "\n",
    "animals.index = ['dove', 'hen', 'duck', 'goose', 'owl', 'hawk', 'eagle', 'fox',\n",
    "                 'dog', 'wolf', 'cat', 'tiger', 'lion', 'horse', 'zebra', 'cow']\n",
    "\n",
    "pl.figure(figsize=(5,5))\n",
    "pl.xticks(np.arange(matrix.shape[1]), animals.columns, rotation=90)\n",
    "pl.yticks(np.arange(matrix.shape[0]), animals.index)\n",
    "pl.title('Animals')\n",
    "_ = pl.imshow(matrix, interpolation='nearest', cmap=cm.binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the features on which we will run our SOM algorithm in order to find an inherent data structure, or similarities between samples.\n",
    "\n",
    "### Definition of the problem\n",
    "\n",
    "In this problem, we will apply the SOM algorithm as follows:\n",
    "    \n",
    "1. Initialize SOM with its parameters (such as size of the map, neighborood size, learning rate...)\n",
    "2. Sequentially present a random sample animal for the map to learn\n",
    "3. Repeat step 2 until the whole dataset was learned t times\n",
    "\n",
    "After the SOM has been \"trained\", we can then visualize it by plotting its U-Matrix (also known as Unified Distance Matrix) which shows the neurons and the distance with their neighbors.\n",
    "To construct a U-Matrix, we need to:\n",
    "\n",
    "1. Create a cell for each neuron\n",
    "2. Create a cell for each 1-1 connection between two neurons\n",
    "3. Assign these new cells the distance between the two neurons they connect (higher is further apart)\n",
    "\n",
    "In the end, if we have a very simple SOM (2x2):\n",
    "\n",
    "    Neuron(0) - Neuron(1)\n",
    "       |           |\n",
    "    Neuron(2) - Neuron(4)\n",
    "\n",
    "The corresponding U-Matrix (2\\*2 -1=3, 2\\*2 -1=3) will be:\n",
    "\n",
    "    Neuron(0) - Dist(0,1) - Neuron(1)\n",
    "       |           |           |\n",
    "    Dist(0,2) -  ?????    - Dist(1,3)\n",
    "       |           |           |\n",
    "    Neuron(2) - Dist(2,3) - Neuron(3)\n",
    "    \n",
    "\n",
    "We are only going to plot the distances.\n",
    "\n",
    "Let us present the animal dataset 10 times to a newly generated kohonen map. We can then compute its U-matrix and plot the result.\n",
    "\n",
    "### First tests with SOM and U-Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmap = KohonenUtils.KohonenMap(20,\n",
    "                               20,\n",
    "                               size_vector=len(animals.columns))\n",
    "n_iter = 10\n",
    "learning_rate = KohonenUtils.ExponentialTimeseries(1, 0.2, n_iter * len(animals.index))\n",
    "neighborhood_size = KohonenUtils.ExponentialTimeseries(4./3 * len(animals.index), 1, n_iter * len(animals.index))\n",
    "\n",
    "kmap.train(animals.values, np.array(animals.index), n_iter, learning_rate, neighborhood_size)\n",
    "\n",
    "kmap.plot_umatrix(plot_names=True, plot_empty=True, fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#006600; color:#fff;padding:5px; font-weight:bold\">Q: Analyze the code (in KohonenUtils.py) to understand what are the uses of each block in the cell right above.</p>\n",
    "\n",
    "<p style=\"background-color:#006600; color:#fff;padding:5px; font-weight:bold\">Q: What do you think about the clustering quality ? </p>\n",
    "\n",
    "<p style=\"background-color:#006600; color:#fff;padding:5px; font-weight:bold\">Q: We plotted the U-Matrix in the previous cell. What does it represent ? </p>\n",
    "\n",
    "<p style=\"background-color:#006600; color:#fff;padding:5px; font-weight:bold\">Q: What do the small stars represent ? What do the bigger circles represent ? </p>\n",
    "\n",
    "<p style=\"background-color:#006600; color:#fff;padding:5px; font-weight:bold\">Q: What does the color in the big circles mean ? </p>\n",
    "\n",
    "<p style=\"background-color:#006600; color:#fff;padding:5px; font-weight:bold\">Q: What does the color in the small stars mean ? </p>\n",
    "\n",
    "<p style=\"background-color:#006600; color:#fff;padding:5px; font-weight:bold\">Q: Plot the learning rate and the neighborhood size. Why do you think we choose them like this? </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 : Animals database clustering with K-Means\n",
    "\n",
    "Now, lets try K-means as a means for clustering the animals. You need to install sklearn first and then run the next cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=3,n_init=1, init='random').fit(animals.values)\n",
    "print (animals.index,kmeans.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#006600; color:#fff;padding:5px; font-weight:bold\">Q: Observe the animals that are grouped together by K-Means and try different numbers of clusters: K=2,3,4, etc. </p>\n",
    "\n",
    "<p style=\"background-color:#006600; color:#fff;padding:5px; font-weight:bold\">Q: n_init is a parameter that automatically asks K-means to try different cluster initializations and selects the best result. init='random' asks K-means to randomly initialize the cluster centroids. Please, try init=’k-means++’ and modify n_init to 10 for example and observe the results. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 3 : Wine database clustering with K-Means\n",
    "\n",
    "Now, use the K-means algorithm to separate the three types of wine in the Wine dataset (K = 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "\n",
    "data = load_wine()\n",
    "features = data.data\n",
    "classes = data.target\n",
    "classes_names = data.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3,n_init=10, init='k-means++').fit(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kmeans.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#006600; color:#fff;padding:5px; font-weight:bold\">Q: Observe the observations that are grouped together by K-Means. </p>\n",
    "\n",
    "<p style=\"background-color:#006600; color:#fff;padding:5px; font-weight:bold\">Q: Count the number of \"bottles\" that are correctly grouped. What is the accuracy of this unsupervised classification? </p>\n",
    "\n",
    "<p style=\"background-color:#006600; color:#fff;padding:5px; font-weight:bold\">Q: Try to improve the performance of the classification. Does normalizing the data increases the accuracy? Does selecting a reduced number of features improves the accuracy? Why?. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
